{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "#  I chose to use SparkSession instead of SparkContext because SparkSession \n",
    "#  eliminates the need to create multiple SparkContext \n",
    "#  (using more memory) maintaining all functionalities of SparkContext (built within Spark 3.0? SparkSession API)\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"practice\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# I downloaded a sample dataset from Kaggle and was playing around with it\n",
    "# Instead of using an RDD, I decided to use DataFrame, which is more efficient\n",
    "# It also organzies things into a table, similar to a relational database (SQL) \n",
    "# might make it easier to paramterize data from SQL queries\n",
    "df = spark.read.csv('cereal.csv', header=True, inferSchema=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows the Column names of DataFrame\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .na.drop(how=\"any\") drops any rows that have null values. There is also \"all\" which only\n",
    "# removes rows if all values are null\n",
    "df.na.drop(how=\"any\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold\n",
    "# the threshold removes rows that don't meet the \"threshold.\" \n",
    "# In that, a row must have a n number of non-null values to not be removed\n",
    "# If the amount of non-null values in a row meets or exceeds the threshold, it stays\n",
    "# otherwise, it is removed\n",
    "\n",
    "df.na.drop(how=\"any\", thresh=15).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the subset parameter only removes null values if they are in the specified subset\n",
    "df.na.drop(subset=['sodium', \"fiber\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is probably the function that is most similar to what i have to do?\n",
    "# lit allows df to add columns in a constant manner\n",
    "\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "# .filter searches the dataframe for null values in accordance with paramters and stores values in another df\n",
    "# .isNull() finds null values in specified column\n",
    "df_sodiumNull = df.filter(df.sodium.isNull())\n",
    "\n",
    "#,WithColumn adds columns to existing dataframe\n",
    "errorLog = df_sodiumNull.withColumn(\"Reason\", lit(\"Sodium Null\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorLog.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorLog = errorLog.union(df.filter(df.potass.isNull()).withColumn(\"Reason\", lit(\"Pot Null\")))\n",
    "errorLog.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----+----+--------+-------+---+------+-----+-----+------+------+--------+-----+------+----+---------+--------------------+\n",
      "|             name| mfr|type|calories|protein|fat|sodium|fiber|carbo|sugars|potass|vitamins|shelf|weight|cups|   rating|              Reason|\n",
      "+-----------------+----+----+--------+-------+---+------+-----+-----+------+------+--------+-----+------+----+---------+--------------------+\n",
      "|   Almond Delight|   R|   C|     110|      2|  2|  null|  1.0| 14.0|     8|  null|      25|    3|   1.0|0.75|34.384843|         Sodium Null|\n",
      "|         Cheerios|   G|   C|     110|      6|  2|  null|  2.0| 17.0|     1|   105|      25|    1|   1.0|1.25|50.764999|         Sodium Null|\n",
      "|100% Natural Bran|null|   C|     120|      3|  5|  null|  2.0|  8.0|     8|   135|       0|    3|   1.0| 1.0|33.983679|         Sodium Null|\n",
      "|      Bran Flakes|   P|   C|      90|      3|  0|  null|  5.0| 13.0|     5|   190|      25|    3|   1.0|0.67|53.313813|         Sodium Null|\n",
      "|        100% Bran|null|   C|      70|      4|  1|   130| null|  5.0|     6|  null|      25|    3|   1.0|0.33|68.402973|            Pot Null|\n",
      "|100% Natural Bran|null|   C|     120|      3|  5|  null|  2.0|  8.0|     8|   135|       0|    3|   1.0| 1.0|33.983679|Vitamins Value In...|\n",
      "+-----------------+----+----+--------+-------+---+------+-----+-----+------+------+--------+-----+------+----+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "errorLog = errorLog.union(df.filter(df.vitamins < 25).withColumn(\"Reason\", lit(\"Vitamins Value Incorrect\")))\n",
    "errorLog.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0e13db5723ba42654ba51c5ce38711cf580992b3c0f828a2f655647c4ed69994"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
